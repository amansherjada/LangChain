{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"FIREWORKS_API_KEY\")\nsecret_value_1 = user_secrets.get_secret(\"LANGCHAIN_API_KEY\")\nsecret_value_2 = user_secrets.get_secret(\"LANGCHAIN_PROJECT\")\nsecret_value_3 = user_secrets.get_secret(\"LANGCHAIN_TRACING_V2\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-02T02:24:43.909919Z","iopub.execute_input":"2024-08-02T02:24:43.910291Z","iopub.status.idle":"2024-08-02T02:24:44.267618Z","shell.execute_reply.started":"2024-08-02T02:24:43.910259Z","shell.execute_reply":"2024-08-02T02:24:44.266489Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install langchain-fireworks","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-08-02T02:24:44.269217Z","iopub.execute_input":"2024-08-02T02:24:44.269521Z","iopub.status.idle":"2024-08-02T02:25:00.438145Z","shell.execute_reply.started":"2024-08-02T02:24:44.269495Z","shell.execute_reply":"2024-08-02T02:25:00.436885Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting langchain-fireworks\n  Downloading langchain_fireworks-0.1.7-py3-none-any.whl.metadata (4.0 kB)\nRequirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /opt/conda/lib/python3.10/site-packages (from langchain-fireworks) (3.9.1)\nCollecting fireworks-ai>=0.13.0 (from langchain-fireworks)\n  Downloading fireworks_ai-0.15.0-py3-none-any.whl.metadata (5.3 kB)\nCollecting langchain-core<0.3.0,>=0.2.26 (from langchain-fireworks)\n  Downloading langchain_core-0.2.27-py3-none-any.whl.metadata (6.2 kB)\nCollecting openai<2.0.0,>=1.10.0 (from langchain-fireworks)\n  Downloading openai-1.37.1-py3-none-any.whl.metadata (22 kB)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain-fireworks) (2.32.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-fireworks) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-fireworks) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-fireworks) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-fireworks) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-fireworks) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-fireworks) (4.0.3)\nRequirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from fireworks-ai>=0.13.0->langchain-fireworks) (0.27.0)\nCollecting httpx-sse (from fireworks-ai>=0.13.0->langchain-fireworks)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from fireworks-ai>=0.13.0->langchain-fireworks) (2.5.3)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from fireworks-ai>=0.13.0->langchain-fireworks) (9.5.0)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-fireworks) (6.0.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-fireworks) (1.33)\nCollecting langsmith<0.2.0,>=0.1.75 (from langchain-core<0.3.0,>=0.2.26->langchain-fireworks)\n  Downloading langsmith-0.1.96-py3-none-any.whl.metadata (13 kB)\nCollecting packaging<25,>=23.2 (from langchain-core<0.3.0,>=0.2.26->langchain-fireworks)\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-fireworks) (8.2.3)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-fireworks) (4.9.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-fireworks) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-fireworks) (1.9.0)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-fireworks) (1.3.0)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-fireworks) (4.66.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-fireworks) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-fireworks) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-fireworks) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-fireworks) (2024.7.4)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-fireworks) (1.2.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->fireworks-ai>=0.13.0->langchain-fireworks) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->fireworks-ai>=0.13.0->langchain-fireworks) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.26->langchain-fireworks) (2.4)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-fireworks)\n  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic->fireworks-ai>=0.13.0->langchain-fireworks) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic->fireworks-ai>=0.13.0->langchain-fireworks) (2.14.6)\nDownloading langchain_fireworks-0.1.7-py3-none-any.whl (16 kB)\nDownloading fireworks_ai-0.15.0-py3-none-any.whl (83 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.2.27-py3-none-any.whl (379 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.8/379.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading openai-1.37.1-py3-none-any.whl (337 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langsmith-0.1.96-py3-none-any.whl (140 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, orjson, httpx-sse, openai, langsmith, fireworks-ai, langchain-core, langchain-fireworks\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: orjson\n    Found existing installation: orjson 3.9.10\n    Uninstalling orjson-3.9.10:\n      Successfully uninstalled orjson-3.9.10\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-cv 0.9.0 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\njupyterlab 4.2.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nspaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fireworks-ai-0.15.0 httpx-sse-0.4.0 langchain-core-0.2.27 langchain-fireworks-0.1.7 langsmith-0.1.96 openai-1.37.1 orjson-3.10.6 packaging-24.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Chat model\n*[ChatFireworks API reference](https://api.python.langchain.com/en/latest/chat_models/langchain_fireworks.chat_models.ChatFireworks.html)*","metadata":{}},{"cell_type":"code","source":"import os\nos.environ['FIREWORKS_API_KEY'] = secret_value_0\nos.environ['LANGCHAIN_API_KEY'] = secret_value_1\nos.environ['LANGCHAIN_PROJECT'] = secret_value_2\nos.environ['LANGCHAIN_TRACING_V2'] = secret_value_3","metadata":{"execution":{"iopub.status.busy":"2024-08-02T02:25:00.439842Z","iopub.execute_input":"2024-08-02T02:25:00.440370Z","iopub.status.idle":"2024-08-02T02:25:00.446468Z","shell.execute_reply.started":"2024-08-02T02:25:00.440324Z","shell.execute_reply":"2024-08-02T02:25:00.445497Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from langchain_fireworks import ChatFireworks\nllm = ChatFireworks(model_name=\"accounts/fireworks/models/mixtral-8x7b-instruct\")","metadata":{"execution":{"iopub.status.busy":"2024-08-02T02:25:00.448726Z","iopub.execute_input":"2024-08-02T02:25:00.449114Z","iopub.status.idle":"2024-08-02T02:25:02.166691Z","shell.execute_reply.started":"2024-08-02T02:25:00.449075Z","shell.execute_reply":"2024-08-02T02:25:02.165515Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Input and get response from LLM\nresult = llm.invoke(\"What is Generative AI?\")\nresult.content","metadata":{"execution":{"iopub.status.busy":"2024-08-02T02:25:02.168621Z","iopub.execute_input":"2024-08-02T02:25:02.169199Z","iopub.status.idle":"2024-08-02T02:25:04.817890Z","shell.execute_reply.started":"2024-08-02T02:25:02.169163Z","shell.execute_reply":"2024-08-02T02:25:04.816855Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"\"Generative AI is a subset of artificial intelligence that uses machine learning models to generate new data similar to the data it was trained on. It can create various types of content, such as text, images, audio, and video. \\n\\nGenerative AI models, like the one I use, learn patterns from the input data and then use that knowledge to create new, unique content. These models can be very powerful and have many applications, including creating realistic computer graphics, synthesizing speech for virtual assistants, generating new ideas for designers, and even helping with creative writing.\\n\\nHowever, it's important to use generative AI responsibly and ethically, as it has the potential to create deepfakes, misleading information, and other harmful content. When used with care, respect, and truth, generative AI can be a valuable tool for enhancing creativity and productivity.\""},"metadata":{}}]},{"cell_type":"markdown","source":"# Prompt templates\n\nPrompt templates help to translate user input and parameters into instructions for a language model. This can be used to guide a model's response, helping it understand the context and generate relevant and coherent language-based output.\n\n- **ChatPromptTemplates**: These prompt templates are used to format a list of messages. These \"templates\" consist of a list of templates themselves. ","metadata":{}},{"cell_type":"code","source":"from langchain_core.prompts import ChatPromptTemplate\n\nprompt = ChatPromptTemplate.from_messages(\n[\n    (\"system\",\"You are an expert AI ENGINEER. Provide me answers based on the questions\"),\n    (\"user\",\"{input}\")\n]\n)\nprompt","metadata":{"execution":{"iopub.status.busy":"2024-08-02T02:25:04.819237Z","iopub.execute_input":"2024-08-02T02:25:04.819558Z","iopub.status.idle":"2024-08-02T02:25:04.827652Z","shell.execute_reply.started":"2024-08-02T02:25:04.819531Z","shell.execute_reply":"2024-08-02T02:25:04.826543Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an expert AI ENGINEER. Provide me answers based on the questions')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"},"metadata":{}}]},{"cell_type":"markdown","source":"# Chain\n\nIn LangChain, a \"chain\" is a sequence of linked steps or components that work together to achieve a specific task, such as information retrieval, data processing, or generating responses. These chains are designed to streamline complex workflows by breaking them down into simpler, manageable steps. Each step in a chain performs a specific function and passes its output to the next step in the sequence.","metadata":{}},{"cell_type":"code","source":"chain = prompt | llm\n\nresult = chain.invoke({\"input\":\"Can you tell me about Artificial Intelligence?\"})\nresult.content","metadata":{"execution":{"iopub.status.busy":"2024-08-02T02:25:04.828880Z","iopub.execute_input":"2024-08-02T02:25:04.829202Z","iopub.status.idle":"2024-08-02T02:25:07.382355Z","shell.execute_reply.started":"2024-08-02T02:25:04.829175Z","shell.execute_reply":"2024-08-02T02:25:07.381226Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"\"Absolutely! Artificial Intelligence (AI) is a field of computer science that focuses on creating intelligent machines that can think and learn like humans. AI involves the development of algorithms and models that enable machines to perform tasks that would normally require human intelligence, such as understanding natural language, recognizing patterns, solving problems, and making decisions.\\n\\nThere are two main types of AI: narrow or weak AI, which is designed to perform a specific task, and general or strong AI, which can perform any intellectual task that a human being can do. Narrow AI is the most common type of AI and includes applications such as voice assistants, recommendation algorithms, and image recognition systems.\\n\\nAI has the potential to transform many industries, from healthcare and finance to transportation and entertainment. However, it also raises important ethical and social questions related to privacy, bias, and job displacement. As an AI engineer, it's essential to consider these issues and design AI systems that are fair, transparent, and beneficial to society.\""},"metadata":{}}]},{"cell_type":"markdown","source":"# Output Parsers\n\nOutput parsers are responsible for taking the output of an LLM and transforming it to a more suitable format. This is very useful when you are using LLMs to generate any form of structured data.","metadata":{}},{"cell_type":"code","source":"from langchain_core.output_parsers import StrOutputParser\n\noutput_parser = StrOutputParser()\n\nchain = prompt | llm | output_parser\nresult = chain.invoke({\"input\":\"Can you tell me about Mistral AI?\"})\nresult","metadata":{"execution":{"iopub.status.busy":"2024-08-02T02:25:07.383631Z","iopub.execute_input":"2024-08-02T02:25:07.383998Z","iopub.status.idle":"2024-08-02T02:25:09.162852Z","shell.execute_reply.started":"2024-08-02T02:25:07.383969Z","shell.execute_reply":"2024-08-02T02:25:09.161832Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"\"Mistral AI is a cutting-edge company based in Paris, France, focused on developing large language models. Founded in 2021 by Idriss Azami, Pierre-Yves Oudeyer, and Clement Delangue, the company is dedicated to creating powerful, safe, and controllable AI technology. Mistral AI's flagship model, Mistral, is a 100-billion parameter language model that aims to rival industry giants like OpenAI's GPT-3. The company's mission is to ensure that AI technology remains accessible and beneficial to all, while maintaining a strong commitment to ethical considerations and responsible AI development.\""},"metadata":{}}]},{"cell_type":"markdown","source":"# Simple Gen AI App","metadata":{}},{"cell_type":"code","source":"!pip install beautifulsoup4","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-08-02T02:25:09.164385Z","iopub.execute_input":"2024-08-02T02:25:09.164734Z","iopub.status.idle":"2024-08-02T02:25:21.158480Z","shell.execute_reply.started":"2024-08-02T02:25:09.164698Z","shell.execute_reply":"2024-08-02T02:25:21.157362Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4) (2.5)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install langchain_community","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-08-02T02:25:21.162738Z","iopub.execute_input":"2024-08-02T02:25:21.163099Z","iopub.status.idle":"2024-08-02T02:25:37.305794Z","shell.execute_reply.started":"2024-08-02T02:25:21.163068Z","shell.execute_reply":"2024-08-02T02:25:37.304570Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Collecting langchain_community\n  Downloading langchain_community-0.2.10-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (3.9.1)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.7)\nCollecting langchain<0.3.0,>=0.2.9 (from langchain_community)\n  Downloading langchain-0.2.11-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.2.27)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.1.96)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (1.26.4)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\nCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.9->langchain_community)\n  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.9->langchain_community) (2.5.3)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain_community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain_community) (24.1)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain_community) (4.9.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.7.4)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain_community) (2.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain_community) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain_community) (2.14.6)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\nDownloading langchain_community-0.2.10-py3-none-any.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain-0.2.11-py3-none-any.whl (990 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\nInstalling collected packages: langchain-text-splitters, langchain, langchain_community\nSuccessfully installed langchain-0.2.11 langchain-text-splitters-0.2.2 langchain_community-0.2.10\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install langchain_huggingface sentence_transformers","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-08-02T02:25:37.307345Z","iopub.execute_input":"2024-08-02T02:25:37.307685Z","iopub.status.idle":"2024-08-02T02:25:50.193778Z","shell.execute_reply.started":"2024-08-02T02:25:37.307642Z","shell.execute_reply":"2024-08-02T02:25:50.192377Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Collecting langchain_huggingface\n  Downloading langchain_huggingface-0.0.3-py3-none-any.whl.metadata (1.2 kB)\nCollecting sentence_transformers\n  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (0.23.4)\nRequirement already satisfied: langchain-core<0.3,>=0.1.52 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (0.2.27)\nRequirement already satisfied: tokenizers>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (0.19.1)\nRequirement already satisfied: transformers>=4.39.0 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (4.42.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.1.2+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.11.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.9.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (1.33)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.75 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (0.1.96)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (2.5.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (8.2.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0->langchain_huggingface) (2023.12.25)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain_huggingface) (2.4)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain_huggingface) (3.10.6)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_huggingface) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_huggingface) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\nDownloading langchain_huggingface-0.0.3-py3-none-any.whl (17 kB)\nDownloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence_transformers, langchain_huggingface\nSuccessfully installed langchain_huggingface-0.0.3 sentence_transformers-3.0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install faiss-cpu","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-08-02T02:25:50.195706Z","iopub.execute_input":"2024-08-02T02:25:50.196731Z","iopub.status.idle":"2024-08-02T02:26:04.023307Z","shell.execute_reply.started":"2024-08-02T02:25:50.196665Z","shell.execute_reply":"2024-08-02T02:26:04.022031Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Collecting faiss-cpu\n  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\nRequirement already satisfied: numpy<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from faiss-cpu) (24.1)\nDownloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.8.0.post1\n","output_type":"stream"}]},{"cell_type":"code","source":"from langchain_community.document_loaders import WebBaseLoader\nfrom langchain_huggingface import HuggingFaceEmbeddings\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_community.vectorstores import FAISS\n\n# Load\ndocs = WebBaseLoader(\"https://python.langchain.com/v0.2/docs/introduction/\").load()\n# Split\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\ndocuments = text_splitter.split_documents(docs)\n# Text to Vector\nembeddings = HuggingFaceEmbeddings(model_name = \"all-MiniLM-L6-v2\")\n# Storing in Vector Store\ndb = FAISS.from_documents(documents, embeddings)\ndb","metadata":{"execution":{"iopub.status.busy":"2024-08-02T02:26:04.025006Z","iopub.execute_input":"2024-08-02T02:26:04.025376Z","iopub.status.idle":"2024-08-02T02:26:29.019345Z","shell.execute_reply.started":"2024-08-02T02:26:04.025346Z","shell.execute_reply":"2024-08-02T02:26:29.018189Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm, trange\n2024-08-02 02:26:11.911921: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-02 02:26:11.912053: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-02 02:26:12.070248: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28884408288a42a898e5a714555bc7b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afc38e569d0b405689b546e48adcecf5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03f67cfcca184ac7adcd65ba5bc0d12e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"733102d8f3534b30a67fe3f8696de4d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4dc200a007e4893b70f67023a33c575"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33b008875f9b40e9b83b247adc088541"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1765a2e09974d3eb5beb82c52c9be4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5330348e7963404cb7761fba8288dc91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91a3fec6334241078e221e712b8f4e23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff4e0315878749ee92d3a15cf12f8b3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93434ce643ae46388a563402ee862025"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<langchain_community.vectorstores.faiss.FAISS at 0x792280043b50>"},"metadata":{}}]},{"cell_type":"code","source":"# query from a vector store db\nquery = \"What is LangChain?\"\nresult = db.similarity_search(query)\nresult[0]","metadata":{"execution":{"iopub.status.busy":"2024-08-02T02:26:29.020549Z","iopub.execute_input":"2024-08-02T02:26:29.021232Z","iopub.status.idle":"2024-08-02T02:26:29.053241Z","shell.execute_reply.started":"2024-08-02T02:26:29.021200Z","shell.execute_reply":"2024-08-02T02:26:29.052185Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"Document(metadata={'source': 'https://python.langchain.com/v0.2/docs/introduction/', 'title': 'Introduction | 🦜️🔗 LangChain', 'description': 'LangChain is a framework for developing applications powered by large language models (LLMs).', 'language': 'en'}, page_content='Introduction | 🦜️🔗 LangChain')"},"metadata":{}}]},{"cell_type":"markdown","source":"`similarity_search_with_score`, which allows you to return not only the documents but also the distance score of the query to them. The returned distance score is L2 distance. Therefore, a lower score is better.","metadata":{}},{"cell_type":"code","source":"query = \"What is LangChain?\"\nresult = db.similarity_search_with_score(query)\nresult[0]","metadata":{"execution":{"iopub.status.busy":"2024-08-02T02:26:29.054480Z","iopub.execute_input":"2024-08-02T02:26:29.055257Z","iopub.status.idle":"2024-08-02T02:26:29.075760Z","shell.execute_reply.started":"2024-08-02T02:26:29.055227Z","shell.execute_reply":"2024-08-02T02:26:29.074749Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(Document(metadata={'source': 'https://python.langchain.com/v0.2/docs/introduction/', 'title': 'Introduction | 🦜️🔗 LangChain', 'description': 'LangChain is a framework for developing applications powered by large language models (LLMs).', 'language': 'en'}, page_content='Introduction | 🦜️🔗 LangChain'),\n 0.5352546)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Chains\n*[Chains Documentation](https://python.langchain.com/v0.1/docs/modules/chains/)*\n\n- **`create_stuff_documents_chain`**: This chain takes a list of documents and formats them all into a prompt, then passes that prompt to an LLM. It passes ALL documents, so you should make sure it fits within the context window of the LLM you are using.","metadata":{}},{"cell_type":"code","source":"from langchain.chains.combine_documents import create_stuff_documents_chain\nfrom langchain_core.prompts import ChatPromptTemplate\n\nprompt = ChatPromptTemplate.from_template(\n    \"\"\"\n    Answer the following question based ONLY on the provided context:\n    <context>\n    {context}\n    </context>\n    \"\"\"\n)\n\ndocument_chain = create_stuff_documents_chain(llm, prompt)\ndocument_chain","metadata":{"execution":{"iopub.status.busy":"2024-08-02T03:23:56.491595Z","iopub.execute_input":"2024-08-02T03:23:56.492691Z","iopub.status.idle":"2024-08-02T03:23:56.503435Z","shell.execute_reply.started":"2024-08-02T03:23:56.492631Z","shell.execute_reply":"2024-08-02T03:23:56.502501Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n  context: RunnableLambda(format_docs)\n}), config={'run_name': 'format_inputs'})\n| ChatPromptTemplate(input_variables=['context'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template='\\n    Answer the following question based ONLY on the provided context:\\n    <context>\\n    {context}\\n    </context>\\n    '))])\n| ChatFireworks(client=<fireworks.client.chat_completion.ChatCompletionV2 object at 0x79230726d210>, async_client=<fireworks.client.chat_completion.ChatCompletionV2 object at 0x79230726eb90>, fireworks_api_key=SecretStr('**********'))\n| StrOutputParser(), config={'run_name': 'stuff_documents_chain'})"},"metadata":{}}]},{"cell_type":"code","source":"!pip install langchain","metadata":{"execution":{"iopub.status.busy":"2024-08-02T02:50:06.798524Z","iopub.execute_input":"2024-08-02T02:50:06.799510Z","iopub.status.idle":"2024-08-02T02:50:18.880809Z","shell.execute_reply.started":"2024-08-02T02:50:06.799476Z","shell.execute_reply":"2024-08-02T02:50:18.879516Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.2.11)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.27)\nRequirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.2)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.96)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (24.1)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (4.9.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.7.4)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain) (2.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"from langchain_core.documents import Document\ndocument_chain.invoke({\n    \"input\":\"What is LangChain?\",\n    \"context\": [Document(str(documents))] # Document accept str\n})","metadata":{"execution":{"iopub.status.busy":"2024-08-02T03:24:01.858639Z","iopub.execute_input":"2024-08-02T03:24:01.859057Z","iopub.status.idle":"2024-08-02T03:24:03.160155Z","shell.execute_reply.started":"2024-08-02T03:24:01.859017Z","shell.execute_reply":"2024-08-02T03:24:03.159032Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"'Based on the provided context, LangChain is a framework for developing applications powered by large language models (LLMs). It simplifies every stage of the LLM application lifecycle, including development, productionization, and deployment. The framework consists of several open-source libraries, including langchain-core, langchain-community, partner packages like langchain-openai, langchain, LangGraph, and LangServe. LangGraph can be used to build robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph. It integrates smoothly with LangChain but can be used without it. The context also includes references to various tutorials, how-to guides, and a conceptual guide for LangChain.'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Retriever\nIn LangChain, a retriever is a key component responsible for fetching relevant documents or information based on a given query. It plays a crucial role in the information retrieval process by searching through a document store (such as a vector store, database, or search index) and returning the most relevant documents that match the query. Retrievers are essential for applications like question-answering systems, chatbots, and any scenario where it's necessary to pull specific pieces of information from a larger corpus of data.","metadata":{}},{"cell_type":"code","source":"retriever = db.as_retriever()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T03:19:44.930513Z","iopub.execute_input":"2024-08-02T03:19:44.931461Z","iopub.status.idle":"2024-08-02T03:19:44.936224Z","shell.execute_reply.started":"2024-08-02T03:19:44.931421Z","shell.execute_reply":"2024-08-02T03:19:44.934966Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"from langchain.chains import create_retrieval_chain\nretriever_chain = create_retrieval_chain(retriever, document_chain)\nretriever_chain","metadata":{"execution":{"iopub.status.busy":"2024-08-02T03:24:10.874388Z","iopub.execute_input":"2024-08-02T03:24:10.874811Z","iopub.status.idle":"2024-08-02T03:24:10.887796Z","shell.execute_reply.started":"2024-08-02T03:24:10.874780Z","shell.execute_reply":"2024-08-02T03:24:10.886842Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"RunnableBinding(bound=RunnableAssign(mapper={\n  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n           | VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x792280043b50>), config={'run_name': 'retrieve_documents'})\n})\n| RunnableAssign(mapper={\n    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n              context: RunnableLambda(format_docs)\n            }), config={'run_name': 'format_inputs'})\n            | ChatPromptTemplate(input_variables=['context'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template='\\n    Answer the following question based ONLY on the provided context:\\n    <context>\\n    {context}\\n    </context>\\n    '))])\n            | ChatFireworks(client=<fireworks.client.chat_completion.ChatCompletionV2 object at 0x79230726d210>, async_client=<fireworks.client.chat_completion.ChatCompletionV2 object at 0x79230726eb90>, fireworks_api_key=SecretStr('**********'))\n            | StrOutputParser(), config={'run_name': 'stuff_documents_chain'})\n  }), config={'run_name': 'retrieval_chain'})"},"metadata":{}}]},{"cell_type":"code","source":"# Get the Response from the LLM\n\nresponse = retriever_chain.invoke({\"input\":\"What is Langchain?\"})\nresponse['answer']","metadata":{"execution":{"iopub.status.busy":"2024-08-02T03:26:47.235973Z","iopub.execute_input":"2024-08-02T03:26:47.236412Z","iopub.status.idle":"2024-08-02T03:26:49.041662Z","shell.execute_reply.started":"2024-08-02T03:26:47.236376Z","shell.execute_reply":"2024-08-02T03:26:49.040520Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"'Based on the provided context, LangChain is a framework that consists of several open-source libraries, including langchain-core, langchain-community, partner packages like langchain-openai and langchain-anthropic, and langchain for building chains, agents, and retrieval strategies. LangGraph is a part of the framework that allows users to build stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph. It can be used with LangChain or independently. LangSmith is another tool in the LangChain ecosystem that helps users move from prototype to production by tracing and evaluating language model applications and intelligent agents. The context also mentions additional resources such as security best practices, integrations, and contributing guidelines.'"},"metadata":{}}]},{"cell_type":"code","source":"response['context']","metadata":{"execution":{"iopub.status.busy":"2024-08-02T03:27:59.371025Z","iopub.execute_input":"2024-08-02T03:27:59.371961Z","iopub.status.idle":"2024-08-02T03:27:59.378327Z","shell.execute_reply.started":"2024-08-02T03:27:59.371928Z","shell.execute_reply":"2024-08-02T03:27:59.377281Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"[Document(metadata={'source': 'https://python.langchain.com/v0.2/docs/introduction/', 'title': 'Introduction | 🦜️🔗 LangChain', 'description': 'LangChain is a framework for developing applications powered by large language models (LLMs).', 'language': 'en'}, page_content='Introduction | 🦜️🔗 LangChain'),\n Document(metadata={'source': 'https://python.langchain.com/v0.2/docs/introduction/', 'title': 'Introduction | 🦜️🔗 LangChain', 'description': 'LangChain is a framework for developing applications powered by large language models (LLMs).', 'language': 'en'}, page_content=\"However, these guides will help you quickly accomplish common tasks.Check out LangGraph-specific how-tos here.Conceptual guide\\u200bIntroductions to all the key parts of LangChain you’ll need to know! Here you'll find high level explanations of all LangChain concepts.For a deeper dive into LangGraph concepts, check out this page.API reference\\u200bHead to the reference section for full documentation of all classes and methods in the LangChain Python packages.Ecosystem\\u200b🦜🛠️ LangSmith\\u200bTrace and evaluate your language model applications and intelligent agents to help you move from prototype to production.🦜🕸️ LangGraph\\u200bBuild stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it.Additional resources\\u200bSecurity\\u200bRead up on our Security best practices to make sure you're developing safely with LangChain.Integrations\\u200bLangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. Check out our growing list of\"),\n Document(metadata={'source': 'https://python.langchain.com/v0.2/docs/introduction/', 'title': 'Introduction | 🦜️🔗 LangChain', 'description': 'LangChain is a framework for developing applications powered by large language models (LLMs).', 'language': 'en'}, page_content=\"Use LangGraph to build stateful agents with first-class streaming and human-in-the-loop support.Productionization: Use LangSmith to inspect, monitor and evaluate your chains, so that you can continuously optimize and deploy with confidence.Deployment: Turn your LangGraph applications into production-ready APIs and Assistants with LangGraph Cloud.Concretely, the framework consists of the following open-source libraries:langchain-core: Base abstractions and LangChain Expression Language.langchain-community: Third party integrations.Partner packages (e.g. langchain-openai, langchain-anthropic, etc.): Some integrations have been further split into their own lightweight packages that only depend on langchain-core.langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture.LangGraph: Build robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph. Integrates smoothly with LangChain, but can be used\"),\n Document(metadata={'source': 'https://python.langchain.com/v0.2/docs/introduction/', 'title': 'Introduction | 🦜️🔗 LangChain', 'description': 'LangChain is a framework for developing applications powered by large language models (LLMs).', 'language': 'en'}, page_content=\"make sure you're developing safely with LangChain.Integrations\\u200bLangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. Check out our growing list of integrations.Contributing\\u200bCheck out the developer's guide for guidelines on contributing and help getting your dev environment set up.Edit this pageWas this page helpful?You can also leave detailed feedback on GitHub.NextTutorialsTutorialsHow-to guidesConceptual guideAPI referenceEcosystem🦜🛠️ LangSmith🦜🕸️ LangGraphAdditional resourcesSecurityIntegrationsContributingCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright © 2024 LangChain, Inc.\")]"},"metadata":{}}]}]}